---
title: "Yield bias"
author: "Lyndon Estes"
date: "July 6, 2015"
output: 
  html_document:
    highlight: tango
    theme: spacelab
    toc: yes 
    number_sections: true
---

# Methods to examine

Ramankutty et al's (2008) procedure for calculating cropland area.  

1. Divide provincial cropland area estimates by total area in each province. 
2. Linear model calculates cropland proportions from model of all satellite landcover classes, creating a 5 minute gridded estimate of cropland in each pixel.
3. These grids are aggregated to administrative level (provinces in our case), and then compared with the provincial statistics. A correction factor is then applied, and _pycnophylactically_ interpolated, which is then used to adjust the gridded estimates.

$$ fcropland_{x,y} = ucf_{x,y} * cf_{x,y}$$

Where ucf is the correction factor and cf is the step 1 modeled cropland fraction estimate for a given pixel (x, y).  

Monfreda et al (2008) then use $fcropland_{x,y}$ in a three step process to calculate the area in administrative units for each crop type, in the following steps: 

1. They divide $fcropland_{x,y}$ by the area of the administrative unit to calculate the fraction of each unit taken up by a particular crop. 

2. They then disaggregate this fraction back onto the gridded data as follows:

$$ fcrop_{x,y} = fcropland_{x,y}\frac{croparea_{pu}}{cropland_{pu}}$$

They assign yields for each crop--obtained from the finest administrative unit available, uniformly across pixels having a non-zero proportion of that crop within the administrative unit. 

They rescaled both area and yield within sub-administrative units to match country totals derived from FAOStat from 1997-2003.  

## Key Questions

1. How does these processes create bias if they are not aggregated by the administrative units to which they are scaled? i.e. If you aggregate by grid cells rather than by administrative units, how does this affect estimates of total production (and therefore things such as calories to be gained by closing yield gaps)  

2. Do any studies use it in this particular way? 

    + Foley et al (2011) estimate amount of calories that could be gained by closing yield gaps.  
    + Find one or two others - maybe Roy with yield trends, or Mueller et al 2012.

# Data

Use SA provinces with GTI to create the amount of agricultural land estimates per province, akin to provincial statistics used by Ramankutty et al (2008). Note: they mentioned SA has 11 administrative units they used, but the publications they cited [here](http://www.statssa.gov.za/publications/DiscussLandAccounts/DiscussLandAccounts.pdf) has just 9 provinces, so maybe they mistakenly counted Lesotho and Swaziland? 

```{r, eval=FALSE}
library(SAcropland)
p_root <- full_path(proj_root("SAcropland"), "SAcropland")
p_fig <- full_path(p_root, "paper/figures/")
p_data <- full_path(p_root, "external/ext_data/")
p_data2 <- full_path(p_root, "data/")
#p_carb <- full_path(p_root, "SAcropland/external/ext_data/carbon/")

# SA provinces
prov <- readOGR("external/ext_data/provinces.sqlite", layer = "provinces")
prov <- prov[prov$id_1 != 9, ]  # remove Princeton Edward Islands
prov[prov$id_1 == 10, "id_1"] <- 9 # reset WC to id 10
load("external/ext_data/MZshapes.Rdata")

# cropland data
load(full_path(p_data, "d_grid_act.rda"))  # actual diffence grids
paths <- full_path(p_data, dir(p_data, paste0("cover*.*11sum_mask.tif$")))
gti <- raster(paths) / 100  # gti 2011

# Reconstruct original landcover estimates
snms <- c("sa30", "globmu", "modmu", "geow")
dlist_1km <- lapply(dlist_act[snms], function(x) x$f1$g2011)
lc_list <- lapply(dlist_1km, function(x) gti - x / 100) 

# plot(lc_list[[1]])
# plot(gti)
# tst <- raster("external/ext_data/geowikisa_masked.tif")  # check
# plot(round(tst / 100 - lc_list[[4]], 4)) # okay

# Create namask to remove all NA areas across datasets
sumna <- function(x) sum(x, na.rm = FALSE)
namask <- calc(stack(gti, stack(lc_list)), sumna)
namask[namask > 0] <- 1
namask2 <- !is.na(namask)  # set NAs to zero
# cellStats(is.na(gti), sum); cellStats(namask2, sum)
fact <- c(5, 10, 25, 50, 100)
```

# Analyses
## Cropland fractions
### Get provincial $cf$ factors from 1 km GTI dataset
```{r, eval=FALSE}
# rasterize provinces and stack with gti raster, convert to data.table
# provr <- rasterize(prov, y = gti, field = "id_1", 
#                    filename = "external/ext_data/provinces.tif")
provr <- raster("external/ext_data/provinces.tif")
provr <- mask(provr, namask)
gtis <- stack(list("prov" = provr, "f" = gti))

# calculate fractions using raster::extract with provinces, to compare speed
# prov_est <- extract(gti, prov, progress = "text")
# prov_estNA <- lapply(prov_est, function(x) x[!is.na(x)])
# cftest <- cbind("carea" = sapply(prov_estNA, sum), 
#                 "parea" = sapply(prov_estNA, length), 
#                 "cf" = sapply(prov_estNA, sum) / sapply(prov_estNA, length))

# data.table calculations
gti_dt <- na.omit(as.data.table.raster(gtis, xy = TRUE))
setkey(gti_dt, prov)
cf <- gti_dt[, list("carea" = sum(f), "parea" = length(f), 
                    "cf" = sum(f) / length(f)), by = prov]
# cftest - cf[, 2:4, with = FALSE]  # close, but diff caused by few NAs in provr 

# data.table approach is much more efficient

```
<a href="#top">Back to top</a>

### Calculate cropland fractions from 1 km landcover sets 

Derived at 1 km resolution rather 10 km (as in Ramankutty et al, 2008), using data.tables to calculate provincial-level correction factors for each
```{r, eval=FALSE}
lcs <- stack(list("prov" = provr, stack(lc_list)))
lcs_dt <- na.omit(as.data.table.raster(lcs, xy = TRUE))
setkey(lcs_dt, prov)
fc <- function(x) sum(x) / length(x)  # fraction functions
lc_cf <- lapply(list(sum, length, fc), function(x) {
  lcs_dt[, lapply(.SD, x), by = prov, .SDcols = snms]
})
names(lc_cf) <- colnames(cf)[-1]
# lcs_dt[, .N, by = prov] == gti_dt[, .N, by = prov]

# correction factors
pcf <- cbind("prov" = prov$id_1, 
             sapply(snms, function(x) cf$cf / lc_cf$cf[, get(x)]))
pcf <- data.table(pcf)

# tst1 <- disaggregate(tst, fact = 10)
# namask <- raster("external/ext_data/namask.tif")
# tst1m <- mask(crop(tst1, namask), mask = namask)
# plot(tst1m - gti$cover2011sum_mask)

```
<a href="#top">Back to top</a>

### Re-scale landcover cropland fraction using $cf$ factors
```{r, eval=FALSE}
# multiply each lc fraction value by correction factor for the particular 
# province
lcs_dta <- copy(lcs_dt)
for(j in snms) {
  for(g in pcf$prov) {
    lcs_dta[prov == g, j := (get(j) * pcf[prov == g, get(j)]), with = FALSE] 
  }
}

# check to see if DT syntax correct
for(i in 1:9) {
  for(j in snms) {
    print(all(lcs_dta[prov == i, get(j)][1:10] == 
                (lcs_dt[prov == i, get(j)] * pcf[i, get(j)])[1:10]))
  }
}

# check to see if the factors resulted in same total area per province
fchk <- lcs_dta[, lapply(.SD, sum), by = prov, .SDcols = snms]
par(mfrow = c(2, 2), mar = rep(1, 4))
for(i in snms) plot(cf[, carea], fchk[, get(i)])  # yup

# how many pixels have fraction > 1 
for(i in 1:9) {
  for(j in snms) {
    print(paste(j, ":", i, ":", 
                  lcs_dta[prov == i, length(which(get(j) > 1))] / 
                            lcs_dta[prov == i, .N]))
  }
}  # several in globcover, modis, and geow

# Adjust these to equal 1 
lcs_dta2 <- copy(lcs_dta)

# function to adjust fractions to fall within 1 while maintaining statistics
force1 <- function(x) {
  a <- x
  while(any(a > 1)) {
    reall <- sum(a[a > 1] - 1)  # total of parts of x > 1, to reallocate
    ind <- which(a < 1)  # parts of x less than 1
    a[a > 1] <- 1
    af <- (reall + sum(a[a < 1])) / sum(a[a < 1])
    a[a < 1] <- a[a < 1] * af
  }
  return(a)
}
# check if works on modis set
hist(lcs_dta[prov == 8, modmu])
hist(force1(lcs_dta[prov == 8, modmu]))
round(sum(force1(lcs_dta[prov == 8, modmu])), 2) == 
  round(sum(lcs_dta[prov == 8, modmu]), 2)

for(j in snms) {
  for(g in pcf$prov) {
    lcs_dta2[prov == g, j := force1(get(j)), with = FALSE] 
  }
}

# Check to see if all fractions <= 1 and that provincial sums are equal
for(i in 1:9) {
  for(j in snms) {
    print(paste(j, ":", i, ":", 
                  lcs_dta2[prov == i, length(which(get(j) > 1))] / 
                            lcs_dta[prov == i, .N], ":", 
                round(lcs_dta2[prov == i, sum(get(j))], 4) == 
                  round(lcs_dta[prov == i, sum(get(j))], 4)))
  }
}  # check

# convert back to rasters
lc_adj <- dt_to_raster(lcs_dta2, CRSobj = sa.shp@proj4string)
lc_adj <- dropLayer(lc_adj, i = 1)
```

### Aggregate adjusted rasters, compare cropland fractions
```{r, eval=FALSE}
tl <- lapply(1:4, function(x) lc_adj[[x]])
names(tl) <- snms
lc_agg <- aggregate_rast_list(fact, tl) # landcover rasters 
rm(tl)
gtic <- crop(gti, lc_adj$sa30)
gti_agg <- aggregate_rast_list(fact, list("gti" = gtic))  # GTI rasters

# compare extents to make sure no offsets - look at in QGIS
# writeRaster(gti_agg$f1$gti, filename = "external/ext_data/test/gti_crop.tif")
# writeRaster(lc_agg$f1$sa30, filename = "external/ext_data/test/sa30_crop.tif")
# looks fine

# tst <- gti_agg$f5$gti - lc_agg$f5$sa30
# plot(tst * 100)

#pct_diff <- function(x, y) (x - y) / x * 100

cf_pct_diff <- lapply(snms, function(x) {
  dif <- lapply(names(lc_agg), function(y) {
    d <- gti_agg[[y]][[1]] - lc_agg[[y]][[x]]
  })
  named_out(dif, names(lc_agg))
})
names(cf_pct_diff) <- snms

# disaggregate for plotting
namaskc <- crop(namask, gtic)
lev <- names(cf_pct_diff[[1]])
disagg <- disaggregate_rast_list(snms, lev, cf_pct_diff, crop(namask, gtic))

stats <- lapply(disagg, function(x) {
  sapply(x, function(y) {
    c(cellStats(y * 100, mean), quantile(y * 100, seq(0, 1, 0.05)))
  })
})
```
<a href="#top">Back to top</a>

Plot for supplementary data
```{r, eval=FALSE}
lims <- c(ceiling(min(sapply(stats, function(x) x[3, ]))), 
          floor(max(sapply(stats, function(x) x[21, ]))))
rng <- range(sapply(stats, range))
brks <- c(rng[1], -50, -30, -20, -10, -5, -1, 1, 5, 10, 20, 30, 50, rng[2])
cols <- colorRampPalette(c("red", "grey80", "blue4"))(length(brks) - 1)

legtext <- "% Difference"
cx <- 1.4
lcol <- "black"
mcap <- c("SA-LC", "GlobCover", "MODIS", "GeoWiki")
lev <- names(disagg[[1]])[-c(2:3)]
lev2 <- c("1 km", "25 km", "50 km", "100 km")
pdf(full_path(p_fig, "cropland_adj_bias_map2.pdf"), height = 6, width = 7)
par(mfrow = c(4, 4), mar = c(0, 0, 0, 0), oma = c(5, 5, 2, 0))
for(i in 1:length(snms)) {
  print(snms[i])
  for(j in 1:length(lev)) {
    print(lev[j])
    plot(sa.shp, lty = 0)
    plot(disagg[[snms[i]]][[lev[j]]] * 100, add = TRUE, col = cols, 
         breaks = brks, legend = FALSE)
  if(j == 1) mtext(mcap[i], side = 2, line = 1, cex = cx)
  if(i == 1) mtext(lev2[j], side = 3, line = 0, cex = cx)
  }
}
flex_legend(ncuts = length(brks) - 1, legend.text = legtext, 
            legend.vals = round(brks), 
            longdims = c(0.2, 0.8), shortdims = c(0.06, 0.01), 
            colvec = cols, #(length(brks) - 1), 
            srt = c(270, 0), horiz = TRUE, textside = "bottom", 
            legend.pos = c(4, 5), leg.adj = list(c(0.25, 0), c(0, -0.5)), 
            cex.val = cx, textcol = lcol, bordercol = lcol)
dev.off()
```
<a href="#top">Back to top</a>

## Yield disaggregation

Following Monfreda et al's (2008) methods. They appear to have used the 2002 district census, so we will use the more recent 2007 census.  

### Process magisterial districts and census data
```{r, eval=FALSE}
# Load in yield dataset and magisterial district polygons
load(full_path(p_data2, "ZAF_adm2.Rdata"))  # magisterial districts
yld <- fread(full_path(p_data, "maize_wheat_2007.csv"))

# Transform magisterial districts, remove Prince Edward Islands
md <- spTransform(gadm, CRSobj = sa.shp@proj4string)
md <- md[md$ID_2 != 313, ]
# round(mean(rgeos::gArea(md, byid = TRUE) / 1000000))
md@data <- md@data[, c("PID", "ID_2", "NAME_1", "NAME_2")]  # trim down columns
# fix a few names that occur more than once to make unique for merging properly
md@data[md$ID_2 == 43, "NAME_2"] <- "MiddelburgEC"
md@data[md$ID_2 == 143, "NAME_2"] <- "RichmondKZ"
md@data[md$ID_2 == 86, "NAME_2"] <- "HeidelbergG"

# check names in two datasets
# match(md@data$NAME_2, yld$district)
# match(yld$district, md@data$NAME_2)
# yld$district[which(!yld$district %in% md@data$NAME_2)]
# sort(md@data$NAME_2[which(!md@data$NAME_2 %in% yld$district)])

# some offline fixing of names ensues
# write.csv(md@data, file = "external/ext_data/mdrect.csv")
# writeOGR(md, dsn = "external/ext_data/mdcheck.sqlite", layer = "mdcheck", 
#          driver = "SQLite")

# reread fixed data, merge a few districts' data where there are synonyms or 1
# district subsumed by another--sum yields, because these districts were 
# probably broken into smaller pieces
# fix same names for merging properly
yld[district == "Middelburg" & province == "Eastern Cape", 
    district := "MiddelburgEC"]
yld[district == "Richmond" & province == "KwaZulu-Natal", 
    district := "RichmondKZ"]
yld[district == "Heidelberg" & province == "Gauteng", 
    district := "HeidelbergG"]

# sumna <- function(x) sum(x, na.rm = TRUE)
mrg <- rbindlist(lapply(unique(yld$merge)[-1], function(x) {
  yld[merge == x, lapply(.SD, sumna), .SDcols = grep("mz|wh", names(yld))]
}))
nms <- sapply(unique(yld$merge)[-1], function(x) {
  nm <- yld[merge == x, district]
})
mnms <- unname(sapply(nms, function(x) x[x %in% md$NAME_2][1]))

keep <- names(yld)[-c(2:5)]
yld2 <- rbind(yld[!district %in% unname(unlist(nms)), keep, with = FALSE], 
              cbind("district" = mnms, mrg))  # adjusted yield dataset

# merge with magisterial district data
mdyld <- sp::merge(md@data, yld2, by.x = "NAME_2", by.y = "district", 
                   all.x = TRUE)  # merge
mdyld <- mdyld[match(mdyld$NAME_2, md@data$NAME_2), ]  # reorder rows correctly
nrow(mdyld) == nrow(md@data)  # check

# calculate yields and total planted ha
mdyld$mzha <- rowSums(mdyld[, grep("mz_ha", colnames(mdyld))])
mdyld$mzyld <- round(rowSums(mdyld[, grep("mz_pr", colnames(mdyld))]) /
                       mdyld$mzha, 1)
mdyld$whha <- rowSums(mdyld[, grep("wh_ha", colnames(mdyld))])
mdyld$whyld <- round(rowSums(mdyld[, grep("wh_pr", colnames(mdyld))]) / 
                       mdyld$whha, 1)

# join to md data
m <- mdyld[match(md$ID_2, mdyld$ID_2), 
           c("ID_2", "NAME_2", "mzha", "mzyld", "whha", "whyld")]
colnames(m)[1:2] <- c("id", "name")
md@data <- cbind(md@data, m)  
all(md$NAME_2 == md$name); all(md$ID_2 == md$id)
md@data <- md@data[, -c(2:4)]

# plot to make sure districts didn't get reordered at all
par(mar = rep(0, 4))
plot(sa.shp)
plot(md, add = TRUE)
plot(md[md$id == 214, ], col = "red", add = TRUE)
plot(md[md$id == 327, ], col = "red", add = TRUE)
plot(md[md$id == 263, ], col = "red", add = TRUE)
plot(md[md$name == "Barberton", ], col = "red", add = TRUE)
```
<a href="#top">Back to top</a>

### Calculate individual crop fractions

Rasterize MDs and calculate individual crop fractions (for maize), for both GTI and adjusted LC cropland fractions
```{r, eval = FALSE}
# mdr <- rasterize(md, provr, field = "id",  
#                  filename = "external/ext_data/mag_dist.tif", overwrite = TRUE)
mdr <- raster("external/ext_data/mag_dist.tif")
mds <- stack(list("md" = crop(mdr, gti_agg$f1$gti), "gti" = gti_agg$f1$gti,
                  lc_adj))  # use gti and lc_adj  
# v <- values((lc_agg$f1$modmu > 1) * 1); sum(v[!is.na(v)])

# data.table calculations
md_dt <- as.data.table.raster(mds, xy = TRUE)
setkey(md_dt, md)
mdarea <- md_dt[, .N, by = md]  # how many km2 in each MD
setnames(mdarea, "N", "mdkm2") 
mdarea <- mdarea[!is.na(md)]  # remove NAs  
setkey(mdarea, md)  
md_dt <- na.omit(md_dt)  # remove NAs from fraction data.tables
varea <- md_dt[, .N, by = md]  # area of non-NA data in MDs
setnames(varea, "N", "vkm2")
setkey(varea, md)
# mdcf <- md_dt[, list("carea" = round(sum(f), 2), "parea" = length(f), 
#                         "cf" = round(sum(f) / length(f), 4)), by = md]
mdva <- mdarea[varea][, fmd:= round(vkm2 / mdkm2, 2)]  # md valid area
# mdcf[, fmd := mdarea[varea][, round(vkm2 / mdkm2, 2)]]  # fraction non-NA in md

# yield data for MDs
ydt <- data.table(md@data[, c("id", "mzha", "mzyld", "whha", "whyld")])
setnames(ydt, "id", "md")
setkey(ydt, "md")
mdvay <- mdva[ydt][is.na(mzha), c("mzha", "mzyld") := 0]
mdvay[is.na(whha), c("whha", "whyld") := 0]
mdvay[, c("mdkm2", "vkm2") := NULL]
# mdcfy[, mfrac := round(((mzha * fmd) / 100) / carea, 4)]  # maize fraction

# calculate crop fractions for each dataset
md_dta <- copy(md_dt)
# md_dt[, lapply(.SD, mean), by = md, .SDcols = c("gti", snms)]
md_lcl <- lapply(c("gti", snms), function(j) {
    DT <- md_dta[, list("carea" = round(sum(get(j)), 2),  # crop area
                        "parea" = length(get(j)),  # non-NA area in MD
                        "cf" = round(sum(get(j)) / length(get(j)), 4)),
                   by = md]
    # calculate crop fraction, adjusting ha first by how much non-NA area there
    # is in MD
    DTy <- DT[mdvay][, mfrac := round(((mzha * fmd) / 100) / carea, 4)]
    DTy[is.na(mfrac), mfrac := 0]  # set mfrac to 0 in 0 cropland areas
    # print(length(which(DTy$mfrac > 1)))  # 5, 4, 15, 9, 4
    #DTy[mfrac > 1, mfrac := 1]  # set to 1 - mostly missing data causing > 1
    DTy
})
names(md_lcl) <- c("gti", snms)
# lapply(md_lcl, function(x) x[, sum(mzha)])
#length(which(is.na(md_lcl$modmu$mfrac)))
#length(which(md_lcl$sa30$mfrac > 1))

par(mfrow = c(2, 3))
for(i in 1:5) hist(md_lcl[[i]]$mfrac)
for(i in 1:5) hist(md_lcl[[i]]$carea)
plot(md_lcl[[1]]$carea, md_lcl[[3]]$carea)
for(i in 1:5) print(length(which(md_lcl[[i]]$mfrac > 1)))
```
<a href="#top">Back to top</a>

Note: when assigning crop fractions, previously we set all fractions > 1 to 1, but now turned this off because Monfreda et al (2010) allow for double-cropping. This is likely not correct, but we are doing it here to be consistent.

### Assign back crop fraction and yield to grid 
```{r, eval=FALSE}
# first in data.tables
asnms <- c("gti", snms)
crop_ay <- lapply(c("gti", snms), function(j) {
  #j <- snms[3]
  DTya <- copy(md_dt)[, list(x, y, md, "f" = get(j))]
  DTya <- DTya[md_lcl[[j]][, list(md, fmd, mfrac, mzyld)]]
  DTya[, fa := f * mfrac]  # this is Monfreda et al equation (pg. 10)
  #print(DTya[which(round(DTya$fa, 4) > 1)[1:4], ])  # check line
  DTya[, mzya := mzyld]  # adjusted yield variable
  DTya[fa == 0, mzya := 0] # set to 0 in pixels having no crop
  DTya
})
names(crop_ay) <- asnms
sapply(crop_ay, function(x) x[, round(sum(fa), 4), by = md][, V1])

# then back to rasters for aggregation
crop_ayr <- lapply(crop_ay, function(x) {
  dt_to_raster(x[, list(x, y, fa, mzya)], CRSobj = sa.shp@proj4string)
})

# redo NA mask because of some slighting shifts
namask <- calc(stack(lapply(crop_ayr, function(x) x$fa)), sumna)
namask[namask > 0] <- 1
namask2 <- !is.na(namask)  # set NAs to zero
# cellStats(is.na(gti), sum); cellStats(namask2, sum)
awgts <- aggregate_rast_list(fact, list(namask2), fun = sum)
awgts <- lapply(awgts, function(x) x[[1]])  # unlist on inner loop
# sumna <- function(x, na.rm = na.rm) sum(x, na.rm = na.rm)
# amsk <- aggregate_rast_list(fact, list(namask2), fun = sumna)
# amsk <- lapply(amsk, function(x) x[[1]])  # unlist on inner loop

```
<a href="#top">Back to top</a>

### Aggregate yields and crop area to coarser resolutions
```{r, eval=FALSE}
# Yield aggregation - aggregating with weighting by crop fraction
# using a custom data.table function to allow this 
lev <- names(disagg[[1]])
wmfun <- parse(text = "sum((mzya * fa) / sum(fa, na.rm = TRUE), na.rm = TRUE)")
sr <- sa.shp@proj4string
d <- c(dim(gti_agg[[1]]$gti)[1:2], xres(gti_agg[[1]]$gti))  # dimensions
cyld <- lapply(lev[-1], function(i) {
  print(i)
  f <- as.integer(gsub("f", "", i))
  il <- lapply(c("gti", snms), function(j) {
    print(paste("...", j))
    rdt <- as.data.table(crop_ayr[[j]], xy = TRUE)
    o <- dt_aggregate(rdt, d[1], d[2], f, wmfun, d[3], "yw")
  })
  named_out(il, asnms)
})
names(cyld) <- lev[-1]

# convert back to rasters
cyldr <- lapply(cyld, function(i) lapply(i, function(j) dt_to_raster(j, sr)))
cyldf1 <- lapply("f1", function(i) {
  f1yld <- lapply(asnms, function(j) crop_ayr[[j]]$mzya)
  named_out(f1yld, asnms)
})
names(cyldf1) <- lev[1]
cyld_agg <- c(cyldf1, cyldr)

plot(cyld_agg$f10$gti)

# check Monfreda's yield data to see how it deals with null areas
monf <- full_path("external/ext_data/monfreda_data/maize_HarvAreaYield_NetCDF",
                  "maize_AreaYieldProduction.nc")
monfmz <- brick(monf, level = 2)
plot(crop(monfmz, spTransform(sa.shp, monfmz@crs)), col = bpy.colors(20))
plot(crop(monfmz, spTransform(sa.shp, monfmz@crs)) > 0)  # almost all SA > 0 

# not implausible that someone would do a direct aggregation of these yield 
# values, without weighting by crop distribution, so this incorrect variant 
# would be: 
cyld_agg2 <- aggregate_rast_list(fact, cyld_agg$f1, mean) # incorrect yld agg

# third variant - aggregate and remove zeros
# first define a function that removes zero yield areas when calculating mean 
# yield--this will allow for aggregation of yields only in those areas having 
# maize, according to Monfreda et al methods
nzmean <- function(x, na.rm) {
  x <- x[(x > 0) & !is.na(x)]
  if(length(x) == 0) {
    m <- 0
  } else if(length(x) > 0) {
    m <- mean(x, na.rm = na.rm)
  }
  return(m)
}
cyld_agg3 <- aggregate_rast_list(fact, cyld_agg$f1, nzmean) # no zero agg

# plot(cyld_agg$f25$modmu - cyld_agg2$f25$modmu)
# plot(cyld_agg$f25$modmu - cyld_agg3$f25$modmu)
wm <- function(x, w) stats::weighted.mean(x, w)

## crop areas
carea <- lapply(1:5, function(x) crop_ayr[[x]]$fa)
names(carea) <- c("gti", snms)

# sumha <- function(x, na.rm) sum(x, na.rm)
carea_agg <- aggregate_rast_list(fact, carea) # crop area, mean aggregation
#carea_agg2 <- aggregate_rast_list(fact, carea, sum) # crop area, sum agg
# plot(carea_agg$f25$globmu)
# plot(carea_agg2$f25$globmu)

# area of each pixel at each aggregation scale
agg_res <- sapply(carea_agg, function(x) res(x$gti)[1]^2 / 10000)  
tareas <- lapply(awgts, function(x) x[[1]] * 100)

# plot(tareas$f50)
#plot((carea_agg$f50$gti * tareas$f50) - (carea_agg2$f50$gti * 100))  # equiv
# ta <- rep(1, 50 * 50)
# a <- runif(50 * 50, 0, 1)
# (sum(a) * 100) / (sum(ta) * 100)
# mean(a) * (sum(ta) * 100)

yat <- list(cyld_agg, cyld_agg2, cyld_agg3)
## check values
# check yields
for(i in lev[-1]) {
  print(paste("factor", i))
  for(j in asnms) {
    print(paste("...", j))
    for(k in 1:3) {
      #ck <- cellStats(cyld_agg$f1$gti, nzmean)
      print(paste("...... type", k, "agg"))
      ck <- crop_ay[[j]][, wm(mzyld, fa)]  # weighted by fraction
      ck2 <- crop_ay$gti[, wm(mzyld, fa)]  # weighted by fraction
      w <- values(carea_agg[[i]][[j]])  # aggregated crop fraction
      x <- values(yat[[k]][[i]][[j]])  # yield values
      ind <- which(x > 0)  # which are non-zero
      x <- x[ind]  # select non zeros
      w <- w[ind]  # select non-zeros
      #w <- w / max(w)
      v <- weighted.mean(x, w)
      d <- round((ck - v) / ck, 2)
      d2 <- round((ck2 - v) / ck2, 2)
      print(c(d, d2))
    }
  }  # type 1 and type 3 aggregations consistent between datasets, across scales
}
rm(yat)

# check aggregated maize fractions
for(i in lev) {
  for(j in snms) {
    ck <- crop_ay[[j]][, sum(fa)] * 100
    d <- round((ck - cellStats(tareas[[i]] * carea_agg[[i]][[j]], sum)) / ck, 2)
    print(d)
  }
}  # all equal
```
<a href="#top">Back to top</a>

### Crop production estimates at different aggregation scales
```{r, eval=FALSE}
# Type A aggregation: multiplying aggregated yields by aggregated fractions
# with crop-fraction weighted aggregate yields
cpagg1 <- lapply(1:length(cyld_agg), function(x) {
  p <- lapply(1:length(cyld_agg[[x]]), function(y) {
    (tareas[[x]] * carea_agg[[x]][[y]]) * cyld_agg[[x]][[y]]
  })
  named_out(p, asnms)
})
names(cpagg1) <- names(agg_res)

# with 0-removed yield aggregation (type 3 yield aggregation)
cpagg3 <- lapply(1:length(cyld_agg3), function(x) {
  p <- lapply(1:length(cyld_agg3[[x]]), function(y) {
    (tareas[[x]] * carea_agg[[x]][[y]]) * cyld_agg3[[x]][[y]]
  })
  named_out(p, asnms)
})
names(cpagg3) <- names(agg_res)

# Type B (formerly II) aggregation: crop production differences when aggregated
# from 1 km calculate production at 1 km
cprod <- lapply(1:length(cyldf1$f1), function(x) {
  cyldf1$f1[[x]] * (carea[[x]] * 100)
})
names(cprod) <- asnms
cpaggII <- aggregate_rast_list(fact, cprod, "sum") # aggregate production

# check production estimates for consistency
pat <- list(cpagg1, cpagg3, cpaggII)
ptype <- c("1", "3", "II")
# check production estimates
for(i in lev[-1]) {
  print(paste("factor", i))
  for(j in asnms) {
    print(paste("...", j))
    for(k in 1:3) {
      print(paste("...... type", ptype[k], "agg"))
      ck <- cellStats(cprod[[j]], sum)  # weighted by fraction
      ck2 <- cellStats(cprod$gti, sum) # weighted by fraction
      v <- cellStats(pat[[k]][[i]][[j]], sum)
      d <- round((ck - v) / ck, 2)
      d2 <- round((ck2 - v) / ck2, 2)
      print(c(d, d2))
    }
  }  # all types consistent across scales
}

# sapply(cprod, function(x) cellStats(x, sum))
# sapply(carea, function(x) cellStats(x, sum))

# Mean production in producing cells at different levels of aggregation
mup <- sapply(lev, function(i) {
  msk <- cpaggII[[i]]$gti > 0
  msk[msk == 0] <- NA
  cpmsk <- msk * cpaggII[[i]]$gti
  cellStats(cpmsk, mean)
})
# sapply(lev, function(i) {
#   msk <- cpagg1[[i]]$gti > 0
#   msk[msk == 0] <- NA
#   cpmsk <- msk * cpagg1[[i]]$gti
#   cellStats(cpmsk, mean)
# })

# mean yield in producing cells at different levels of aggregation
muy <- sapply(lev, function(i) {
  w <- values(carea_agg[[i]]$gti)  # aggregated crop fraction
  x <- values(cyld_agg[[i]]$gti)  # yield values
  ind <- which(x > 0)  # which are non-zero
  x <- x[ind]  # select non zeros
  w <- w[ind]  # select non-zeros
  v <- weighted.mean(x, w, na.rm = TRUE, )
  v
})

# calculate differences between them
# check first that cpagg1 and II are equivalent, make cpaggII master
for(i in lev) {
  for(j in snms) {
    a <- (cpagg1[[i]]$gti - cpagg1[[i]][[j]]) - 
      (cpaggII[[i]]$gti - cpagg1[[i]][[j]])
    print(round(cellStats(a, sum), 5))
  }
}
# Production differences
ilist <- list(names(cpagg1[[1]])[-1], names(cpagg1), "gti")
list1 <- lapply(cpaggII, function(x) x[[1]])
list2 <- lapply(cpagg1, function(x) x[-1])
p_diff1 <- rast_list_math(ilist, list1, list2, expr = "a - b")  # type 1 agg
list2 <- lapply(cpagg3, function(x) x[-1])
p_diff2 <- rast_list_math(ilist, list1, list2, expr = "a - b")  # type 3 agg
list2 <- lapply(cpaggII, function(x) x[-1])
p_diff3 <- rast_list_math(ilist, list1, list2, expr = "a - b")  # type II agg
# pmu <- as.data.table.raster(cpagg3$f1$globmu)[layer > 0, mean(layer)]

# yield differences
list1 <- lapply(cyld_agg, function(x) x[1])
list2 <- lapply(cyld_agg, function(x) x[-1])
y_diff1 <- rast_list_math(ilist, list1, list2, expr = "a - b")  # type 1 
# type 2 (non-zero)
list2 <- lapply(cyld_agg3, function(x) x[-1]) # reuse cyld_agg for a, b/c correct
y_diff2 <- rast_list_math(ilist, list1, list2, expr = "a - b")  # type 2

# convert them to percent differences relative to the mean pixel-wise production
# plot(y_diff2$sa30$f25$gti)
pdiffs <- lapply(list(p_diff1, p_diff2, p_diff3), function(x) {
  l1 <- lapply(snms, function(y) {
    l2 <- lapply(lev, function(z) {
      x[[y]][[z]]$gti / mup[z] * 100
    })
    named_out(l2, lev)
  })  
  named_out(l1, snms)
})
names(pdiffs) <- paste0("pd", 1:3)

ydiffs <- lapply(list(y_diff1, y_diff2), function(x) {
  l1 <- lapply(snms, function(y) {
    l2 <- lapply(lev, function(z) {
      x[[y]][[z]]$gti / muy[z] * 100
    })
    named_out(l2, lev)
  })  
  named_out(l1, snms)
})
names(ydiffs) <- paste0("yd", 1:2)

# disaggregate for plotting
lev <- names(y_diff2[[1]])
p_diff1d <- disaggregate_rast_list(snms, lev, pdiffs$pd1, namask)
p_diff2d <- disaggregate_rast_list(snms, lev, pdiffs$pd2, namask)
p_diff3d <- disaggregate_rast_list(snms, lev, pdiffs$pd3, namask)
y_diff1d <- disaggregate_rast_list(snms, lev, ydiffs$yd1, namask)
y_diff2d <- disaggregate_rast_list(snms, lev, ydiffs$yd2, namask)

# stats for plotting
dstats <- function(dlist) {
  statsd <- lapply(dlist, function(x) {
    sapply(x, function(y) {
      c(cellStats(y, mean), quantile(y, seq(0, 1, 0.05)))
    })
  })
}
stats_pd1 <- dstats(p_diff1d)
stats_pd2 <- dstats(p_diff2d)
stats_pd3 <- dstats(p_diff3d)
stats_yd1 <- dstats(y_diff1d)
stats_yd2 <- dstats(y_diff2d)
# cbind(stats_yd1$geow[, 4], stats_yd2$geow[, 4])
```
<a href="#top">Back to top</a>

### Plot difference maps
```{r, eval=FALSE}
dnms <- ls()[grep("[y_|p_]diff*.*d", ls())]
stnms <- ls()[grep("stats_", ls())]
disaggl <- lapply(dnms, function(x) get(x))
statsl <- lapply(stnms, function(x) get(x))
rng <- lapply(statsl, function(x) {
  ilims <- c(ceiling(min(sapply(x, function(y) y[3, ]))), 
             floor(max(sapply(x, function(y) y[21, ]))))
  olims <- range(sapply(x, function(y) range(y)))
  c(olims[1], ilims, olims[2])
})

fnms <- c(paste0("prod_bias_map_", 1:3, ".pdf"), 
          paste0("yld_bias_map_", 1:2, ".pdf"))  # output names
# legtext <- c(rep("tons", 3), rep("tons/ha", 2))
legtext <- rep("%", 5)
cx <- 1.4
lcol <- "black"
mcap <- c("SA-LC", "GlobCover", "MODIS", "GeoWiki")
lev <- names(p_diff1d[[1]])[-c(2:3)]
lev2 <- c("1 km", "25 km", "50 km", "100 km")

rnder <- function(x) {
  dig <- nchar(max(round(x)))
  rmat <- cbind(1:8, c(1, 5, 10, 20, 50, 100, 100, 1000))
  rnd <- rmat[dig, 2]
  round(c(floor(x[1] / rnd), ceiling(x[2] / rnd))) * rnd 
}
div_breaks <- function(olim, ilim, ibrk) {
  il <- rnder(ilim) 
  ol <- c(floor(olim[1]), ceiling(olim[2]))
  brks <- c(ol[1], seq(il[1], -ibrk, abs(floor(il[1]) - -ibrk) / 4), 
            seq(ibrk, il[2], abs(ceiling(il[2]) - ibrk) / 4), ol[2])
  brks
}

rng2 <- lapply(rng, function(x) {
  x[2:3] <- c(-100, 100)
  x
})
brksl <- lapply(rng2, function(x) {
  c(floor(x[1:2]), c(-50, -25, -10, -1, 1, 10, 25, 50), ceiling(x[3:4]))
})

for(i in 1:length(statsl)) {
  # i <- 1
  #lim <- rng[[i]]
  # lim <- rng2[[i]]
  # brks <- div_breaks(olim = lim[c(1, 4)], ilim = lim[2:3], 
  #                   ibrk = 0.01 * min(abs(lim[2:3])))
  # if(i < 4) brks <- round(brks)
  # if(i >= 4) brks <- round(brks, 1)
  print(paste("figure", i, "of", length(statsl)))
  brks <- brksl[[i]]
  cols <- colorRampPalette(c("red", "grey80", "blue4"))(length(brks) - 1)
  cols[c(1, length(cols))] <- c("darkred", "purple3")
  pdf(full_path(p_fig, fnms[i]), height = 6, width = 7)
  par(mfrow = c(4, 4), mar = c(0, 0, 0, 0), oma = c(5, 5, 2, 0))
  for(j in 1:length(snms)) {
    print(snms[j])
    for(k in 1:length(lev)) {
      rl <- disaggl[[i]]
      print(lev[k])
      plot(sa.shp, lty = 0)
      plot(rl[[snms[j]]][[lev[k]]], add = TRUE, col = cols, 
           breaks = brks, legend = FALSE)
      if(k == 1) mtext(mcap[j], side = 2, line = 1, cex = cx)
      if(j == 1) mtext(lev2[k], side = 3, line = 0, cex = cx)
    }
  }
  flex_legend(ncuts = length(brks) - 1, legend.text = legtext[i], 
              legend.vals = brks, longdims = c(0.2, 0.8), 
              shortdims = c(0.1, 0.01), 
              colvec = cols, #(length(brks) - 1), 
              srt = c(270, 0), horiz = TRUE, textside = "bottom", 
              legend.pos = c(4, 5), leg.adj = list(c(0.1, 0.3), c(0, -0.5)), 
              cex.val = cx - 0.4, textcol = lcol, bordercol = lcol)
  dev.off()
}  

lev <- names(p_diff1d[[1]])  # reset levs
```
<a href="#top">Back to top</a>

From the above it is clear that the nature in which aggregation of yields are done has some impact on both yield and production estimates. There are three types of yield aggregation that can be done: 

  1. __Type 1__: weighted mean averaging, with the weights provided by crop fractions. This produces correct country-level average yields (<1-2% different) across scales and between datasets, provided that the averaging is weighted by the cropland fractions that were aggregated to the level from which the country-level yield estimate is being calculated
  
  2. __Type 2__: Straight averaging, which results in diluted country-level yield estimates. Incorrect, and should be obvious that this wouldn't be done, so we haven't pursued it here. 
  
  3. __Type 3__: or zero-removed averaging, where only areas having fraction of that crop contribute to the aggregated average. As with __Type 1__, this produces correct country level estimates when weighting by cropland fraction, but it does not produce correct production estimates, probably because it inflates the value of high-yielding irrigated areas out towards the dry west, where the crop fractions are small. (see below) 
    
There are also two ways of aggregating production estimates: 

  1.  __Type A__: Aggregating yield and crop area separately, then multiplying. This is correct with __Type 1__ yield aggregation, and producing identical production estimates to __Type II__, but not with the other two types of yield aggregation.    
  
  2.  __Type B__: Calculating production at the base resolution, then aggregating by sum. This should be the correct way of doing it. 
  
Why would someone do a yield aggregation, when you have the gridded estimates?  To calculate values and compare them to a coarser resolution product, for instance, or to get a country-level average. 

Causes for bias concern to examine: 

  + Bias in yield gap estimates, and how much closing that could affect contribution of closing gaps to boosting production.
  
  + Country-level statistics might cancel out bias, but if bias of one type of sign is spatially correlated with the driver of values in yield gaps, then that would bias larger-scale estimates of gap closure potential.
  
  + These concerns apply to all resolutions.  
  
      + ___Note: investigate this by look at correlation between rainfall and yield bias patterns.___ 
  
## Bias statistics

Following methods developed in [carbon-bias](carbon-bias.html)
```{r, eval=FALSE}
wm <- function(x, w) stats::weighted.mean(x, w)
wma <- function(x, w) stats::weighted.mean(abs(x), w)

# create mask for non-cropland areas, unioning GTI and LC areas with maize
# estimates -- probably not needed if doing production estimates.  
lev <- names(y_diff1[[1]])

# first check aggregation to make yield aggregation variants have common area,
# so that just one lc_union is needed
for(i in lev) {
  for(j in snms) {
    print(cellStats(cyld_agg[[i]][[j]] > 0 & cyld_agg3[[i]][[j]] == 0, sum))
    #print(cellStats(carea_agg[[i]][[j]] > 0 & cyld_agg[[i]][[j]] == 0, sum))
  }
}  # all zeros

snms <- names(p_diff1)
lcu <- lapply(lev, function(x) {
  lcb <- lapply(snms, function(y) {
    gti_gt0 <- Which(carea_agg[[x]][[1]] > 0)
    lc_gt0 <- Which(carea_agg[[x]][[y]] > 0)
    all_gt0 <- gti_gt0 + lc_gt0
    all_gt0[all_gt0 > 0] <- 1
    all_gt0
  })
  named_out(lcb, snms)
})
names(lcu) <- lev
# plot(lc_union$f50$modmu)
# plot(gti_agg$f50$gti)

# cropland cover bins, for looking at error as a function of cover
binv <- seq(0, 1, 0.05)
bins <- lapply(gti_agg, function(x) {
  cut(x$gti, breaks = binv, include.lowest = TRUE)
})
# save(bins, awgts, lcu, p_diff1, wm, wma, p_diff1, cyld_agg, cyld_agg3, 
#      carea_agg, cpagg1, cpagg3, cpaggII, p_diff2, p_diff3, y_diff1, 
#      y_diff2, snms, lev, file = "external/ext_data/yield-bias.rda")
# load("external/ext_data/yield-bias.rda")
# reval <- p_diff1[[2]][[1]][[1]]  # hack in case there is a 3rd level
# revall <- p_diff1
# rmask <- lcu[[2]][[1]]
# rmaskl <- lcu
# rwgts <- awgts[[2]]
# rwgtsl <- awgts
# rbins <- bins[[2]]
# rbinsl <- bins
# fun <- sum
# stnm <- "sum"
# evalnm <- "bias"
# rnd = 2; trim_wgt = TRUE; silent = FALSE; weighted = TRUE
# wm <- function(x, w) stats::weighted.mean(x, w) 
# tst <- data.table("a" = runif(20, 0, 1), 
#                   "w" = sample(20:100, 20, replace = TRUE))
# tst$w <- 0
# tst[, lapply(.SD, sum, w), .SDcols = 1:2]
# weighted.mean(tst$a, tst$w)
# mean(tst$a)
# sum(tst$a)

# selection variables
a <- bias_stats_list(bins, awgts, lcu, p_diff1, wm, "mu", "bias", TRUE)
b <- bias_stats_list(bins, awgts, lcu, p_diff1, wma, "mua", "bias", TRUE)
d <- bias_stats_list(bins, awgts, lcu, p_diff1, sum, "sum", "bias", FALSE)
pd1_st <- rbind(a, b, d)
a <- bias_stats_list(bins, awgts, lcu, p_diff2, wm, "mu", "bias", TRUE)
b <- bias_stats_list(bins, awgts, lcu, p_diff2, wma, "mua", "bias", TRUE)
d <- bias_stats_list(bins, awgts, lcu, p_diff2, sum, "sum", "bias", FALSE)
pd2_st <- rbind(a, b, d)
a <- bias_stats_list(bins, awgts, lcu, p_diff3, wm, "mu", "bias", TRUE)
b <- bias_stats_list(bins, awgts, lcu, p_diff3, wma, "mua", "bias", TRUE)
d <- bias_stats_list(bins, awgts, lcu, p_diff3, sum, "sum", "bias", FALSE)
pd3_st <- rbind(a, b, d)
a <- bias_stats_list(bins, awgts, lcu, y_diff1, wm, "mu", "bias", TRUE)
b <- bias_stats_list(bins, awgts, lcu, y_diff1, wma, "mua", "bias", TRUE)
yd1_st <- rbind(a, b)
a <- bias_stats_list(bins, awgts, lcu, y_diff2, wm, "mu", "bias", TRUE)
b <- bias_stats_list(bins, awgts, lcu, y_diff2, wma, "mua", "bias", TRUE)      
yd2_st <- rbind(a, b)

# Output statistics
p1mu <- extract_stat(lev, snms, "all", "mu", "bias", pd1_st)  # identical to p3
p1ma <- extract_stat(lev, snms, "all", "mua", "bias", pd1_st)  # identical to p3
p1sm <- extract_stat(lev, snms, "all", "sum", "bias", pd1_st)  # identical to p3
p2mu <- extract_stat(lev, snms, "all", "mu", "bias", pd2_st)
p2ma <- extract_stat(lev, snms, "all", "mua", "bias", pd2_st)
p2sm <- extract_stat(lev, snms, "all", "sum", "bias", pd2_st)
p3mu <- extract_stat(lev, snms, "all", "mu", "bias", pd3_st)
p3ma <- extract_stat(lev, snms, "all", "mua", "bias", pd3_st)
p3sm <- extract_stat(lev, snms, "all", "sum", "bias", pd3_st)
y1mu <- extract_stat(lev, snms, "all", "mu", "bias", yd1_st)
y1ma <- extract_stat(lev, snms, "all", "mua", "bias", yd1_st)
y2mu <- extract_stat(lev, snms, "all", "mu", "bias", yd2_st)
y2ma <- extract_stat(lev, snms, "all", "mua", "bias", yd2_st)

# Older variant of code from compare-landcover.Rmd to evaluate whether newer DT
# version is finding correct results
i <- y_diff1 #pdiff_3 # p_diff1
jdt <- yd1_st # pd3_st # pd1_st
bv <- "mu"
for(chk in list(c("modmu", "f25"), c("geow", "f10"), c("sa30", "f50"), 
                c("globmu", "f1"))) {
  x <- chk[1] 
  y <- chk[2] 
  print(paste(".", x, "..", y))
  rs <- lcu[[y]][[x]] 
  rs[rs == 0] <- NA
  l3 <- i[[x]][[y]][[1]]  
  o <- rs * l3
  w <- awgts[[y]][[1]] * rs
  wmu <- weighted.mean(getValues(o), getValues(w), na.rm = TRUE)
  print(jdt[ol == y & il == x & bvals == bv & bin == "all", bias] ==
          round(wmu, 2))
}  # check

```
<a href="#top">Back to top</a>

### Bias plots
```{r, eval=FALSE}
alph <- c(225, 40)
#Ccols <- brewer.pal(n = 7, name = "Greys")
# LC2 <- c(LC[-grep("second|grass", LC)], "all")
# xax <- seq(0, 7, 6 / (length(yax) - 2)); length(xax)
x <- c(0, 3, 6, 9, 12, 15)
w <- 3 / 8
xo <- (cumsum(rep(w, 8)) - w / 2)[-c(2, 4, 6, 8)]
#x + xo[j] + o[k]
o <- c(0, w)
xa <- sapply(x, function(x) x + xo)
cx <- c(2, 1.25, 1, 1)
g1 <- "grey90"

# mul <- c("p1mu", "p2mu", "p3mu", "y1mu", "y2mu")
mul <- c("p2mu", "p3mu", "y1mu", "y2mu")
#mal <- c("p1ma", "p2ma", "p3ma", "y1ma", "y2ma")
mal <- c("p2ma", "p3ma", "y1ma", "y2ma")
malmul <- list(mal, mul)
#pyl <- c("mup", "mup", "mup", "muy", "muy")
pyl <- c("mup", "mup", "muy", "muy")

xl <- c(-0.5, 18)
yl <- c(-70, 80)
shd <- c(4.5, 10.5, 16.5)
cols <- c("red", "orange3", "green4", "blue")
lcnms <- c("SA LC", "GlobCover", "MODIS", "Geowiki")
pchs <- c("*", "+", "o", "x", "-")

#yl <- range(mu[, 3:8, with = FALSE], mua[, 3:8, with = FALSE])
#yl <- round(yl / 10) * 10
yax <- seq(yl[1], yl[2], 10)
xax <- seq(1, 6, 5 / (length(yax) - 1))

pdf(full_path(p_fig, "yield_bias_scale2.pdf"), height = 7, width = 7)
par(mar = rep(1, 4), oma = c(2, 2, 0, 0), mgp = c(1, 0.5, 0), tcl = -0.3)
plot(xl, yl, pch = "", yaxt = "n", xaxt = "n", xaxs = "i", yaxs = "i", 
     ylab = "", xlab = "")#,
for(i in shd) polyfunc2(x = i, y = yl, w = 3, col = g1, bcol = g1, lwd = 1)
polyfunc2(x = 8.75, y = yl, w = 18.5, col = "transparent", bcol = "black")
grid(NA, length(yax), lwd = 1, lty = 1)
lines(c(-1, 18), c(0, 0), lwd = 2, col = "grey80")
for(ii in 1:length(lev)) {
  lv <- lev[ii]
  for(i in 1:length(snms)) {
    pchs1 <- pchs
    nm <- snms[i]
    for(k in 1:length(malmul)) {
      mm <- malmul[[k]]
      v <- sapply(1:length(mm), function(j) {
        round(get(mm[j])[ol == lv & il == nm,  bias] / get(pyl[j])[lv] * 100, 1)
      })
      pcol <- makeTransparent(cols[i], alpha = alph[k])
      polyfunc2(xa[i, ii] + o[k], range(v), w = w, col = pcol, bcol = pcol)
      xx <- rep(x[ii] + xo[i] + o[k], length(v))
      points(xx, v, pch = pchs, cex = cx)
    }
  }
}
axis(1, at = seq(1.5, 18.5, 3), labels = c(1, fact))
axis(2, at = yax, labels = yax, las = 2)
mtext(side = 1, text = "Resolution (km)", outer = TRUE, line = 0.5)
mtext(side = 2, text = "% bias", outer = TRUE, line = 1)
legend(x = 12.4, y = -40, legend = lcnms, pch = 15, col = cols, adj = 0,
       pt.cex = 1.5, bty = "n", cex = 0.8, x.intersp = 0.5)
legend(x = 11.9, y = -40, legend = rep("", 4), pch = 15, adj = 0, 
       col = makeTransparent(cols, alpha = alph[2]), pt.cex = 1.5, bty = "n", 
       cex = 0.8)
text(x = 12.7, y = -42, labels = "Absolute", srt = 45, adj = c(0, 0), cex = 0.8)
text(x = 12.2, y = -42, labels = "Actual", srt = 45, adj = c(0, 0), cex = 0.8)
legend(x = 12.1, y = 65, legend = c("Prod I", "Prod II", "Yield 1", "Yield 2"), 
       pch = pchs, pt.cex = c(2.5, 1.5, 1.5, 1.5), bty = "n", cex = 0.8)
dev.off()
```
<a href="#top">Back to top</a>

## The impacts of spatial patterns in bias

Using yield gap estimates as an indicator. First we'll bring in mean rainfall as a means of calculating a spatial correlation in yield gap estimates. Using data from the Princeton Global Forcing dataset, downloaded from the Africa Flood and Drought Monitor.
```{r, eval=FALSE}
# rainfall layer prepared for SA crop subsidy analysis
load("external/ext_data/climate/mag_dist_clim.rda")
pre <- calc(pre2, mean)  # 31 year mean rainfall for Africa
p4s <- projection(raster(nrow = 10, ncol = 10)) # GCS
presa <- crop(pre, spTransform(sa.shp, p4s))  # crop to SA
projection(presa) <- p4s  
presa <- projectRaster(presa, lcu$f25$sa30)  # project to Albers
presa <- mask(presa, awgts$f25, maskvalue = 0)  # mask
presa1k <- disaggregate(presa, fact = 25)

# reclassify rainfalls to nearest 100 mm, tweak to catch lower and upper bound
rclmat <- cbind(seq(50, 750, 100), seq(150, 850, 100), seq(100, 800, 100))
rclmat[1] <- 15
rclmat[8, 2] <- 875
prebin <- crop(reclassify(presa1k, rclmat), namask)  # rainfall bins

# Assume a yield gap over-estimated by 100% in a particular location, say the 
# 300-400 mm isohyet
prez <- (prebin == 300) | (prebin == 400)
notprez <- (prebin < 300) | (prebin > 400)
g1 <- 0
g2 <- 1

ygap_bias <- sapply(lev, function(x) {
  if(x != "f1") { 
    preagg <- aggregate(prebin, fact = as.numeric(gsub("f", "", x)), fun = modal)
  } else {
    preagg <- prebin
  }
  prez <- (preagg == 300) | (preagg == 400)
  notprez <- (preagg < 300) | (preagg > 400)
  sapply(snms, function(y) {
    yg <- (g1 * cyld_agg[[x]]$gti * notprez) + (g2 * cyld_agg[[x]]$gti * prez)
    yg2 <- (g1 * cyld_agg[[x]][[y]] * notprez) + (g2 * cyld_agg[[x]][[y]] * prez)
    pg <- tareas[[x]] * carea_agg[[x]]$gti * yg
    pg2 <- tareas[[x]] * carea_agg[[x]][[y]] * yg2
    cellStats(pg - pg2, sum) / cellStats(pg, sum) * 100
  })
})

# Assume a yield gap over-estimated by 100% in 400 mm isohyet
ygap_bias2 <- sapply(lev, function(x) {
  if(x != "f1") { 
    preagg <- aggregate(prebin, fact = as.numeric(gsub("f", "", x)), fun = modal)
  } else {
    preagg <- prebin
  }
  prez <- preagg == 400
  notprez <- preagg != 400
  sapply(snms, function(y) {
    yg <- (g1 * cyld_agg[[x]]$gti * notprez) + (g2 * cyld_agg[[x]]$gti * prez)
    yg2 <- (g1 * cyld_agg[[x]][[y]] * notprez) + (g2 * cyld_agg[[x]][[y]] * prez)
    pg <- tareas[[x]] * carea_agg[[x]]$gti * yg
    pg2 <- tareas[[x]] * carea_agg[[x]][[y]] * yg2
    cellStats(pg - pg2, sum) / cellStats(pg, sum) * 100
  })
})

# Assume a yield gap over-estimated by 100% in 500 mm isohyet
ygap_bias3 <- sapply(lev, function(x) {
  if(x != "f1") { 
    preagg <- aggregate(prebin, fact = as.numeric(gsub("f", "", x)), fun = modal)
  } else {
    preagg <- prebin
  }
  prez <- preagg == 500
  notprez <- preagg != 500
  sapply(snms, function(y) {
    yg <- (g1 * cyld_agg[[x]]$gti * notprez) + (g2 * cyld_agg[[x]]$gti * prez)
    yg2 <- (g1 * cyld_agg[[x]][[y]] * notprez) + (g2 * cyld_agg[[x]][[y]] * prez)
    pg <- tareas[[x]] * carea_agg[[x]]$gti * yg
    pg2 <- tareas[[x]] * carea_agg[[x]][[y]] * yg2
    cellStats(pg - pg2, sum) / cellStats(pg, sum) * 100
  })
})

# Print out combined results to latex table
scen <- c(rep("300-400 mm", nrow(ygap_bias)), rep("400 mm", nrow(ygap_bias)),
          rep("500 mm", nrow(ygap_bias)))
ygaps <- cbind.data.frame(scen, "sensor" = rep(snms, 3), 
                          rbind(ygap_bias, ygap_bias2, ygap_bias3))
ygap_xtab <- xtable::xtable(ygaps, digits = 1)
print(ygap_xtab, type = "latex", 
      file = "paper/figures/ygap-spat-bias.tex")

```
<a href="#top">Back to top</a>

The actual impact of the spatial bias is fairly low, being largely cancelled out by biases in other direction in other areas. This illustrates the advantage of a statistically constrained approach to crop area estimates.  

```{r, eval=FALSE, echo=FALSE}
# looking into pycnophylactic interpolation of correction factors
# install.packages("pycno")
require(pycno)

# pycno package example
nc_sids <- readOGR(system.file("shapes/sids.shp", package="maptools")[1], 
                   layer = "sids")
nc_sids@proj4string <- CRS("+proj=longlat +ellps=clrk66")
births74 <- pycno(nc_sids, nc_sids$BIR74, 0.05, converge = 1)
plot(raster(as(births74, "SpatialPixelsDataFrame")))
plot(nc_sids,add=TRUE)

# on out data
provr <- rasterize(prov, y = gti_agg$f10$gti, field = "id_1")
prov2 <- rasterToPolygons(provr, dissolve = TRUE)
colnames(prov2@data) <- "provid"
prov2@data <- cbind(prov2@data, do.call(cbind, pcf))

snms <- colnames(prov2@data)[2:5]
cfrs <- lapply(snms, function(x) {
  #x <- snms[1]
  cfr <- pycno(prov2, prov2@data[, x], 10000, converge = 1)
  cfr_spp <- as(cfr, "SpatialPixelsDataFrame")
  cfrr <- raster(cfr_spp)
  cfrrs <- resample(x = cfrr, provr, method = "ngb")
})
names(cfrs) <- snms
plot(cfrs$sa30)

reclmat <- cbind(1:9, pcf$sa30)  # reclass matrix
cfr <- reclassify(provr, reclmat)  # assign cf values to rasterized
tst <- (lc_agg$f10$sa30 * cfr)

# this interpolation does not make sense in terms of leading to a correction 
# that ends up with cropland fractions matching the provincial estimates of 
# cropland area, at least not given the equations provided by Ramankutty et al
# (2008). The provincial level correction factor should not be disaggregated so # that the summed correction factors add back up to the original correction
# factor.

cft <- 18 / sum(rep(2, 10))
sum(rep(2, 10) * cft)



```



